# ğŸ¤– Intelligent Navigation RL Research  

## ğŸ“š Content

- [Overview](#Overview)
- [Model-free-I](#Model-free-I)
- [Model-free-II](#Model-free-II)
- [Model-based](#Model-based)


## ğŸŒŸ 0. Overview

"To address the challenges of **low learning efficiency and poor generalization** in reinforcement learning for visual navigation tasks, we focus on image-goal navigation in the Habitat simulator and explore a technical pathway from model-free to model-based reinforcement learning approaches. Compared with existing methods on the image-goal navigation benchmark, our approach demonstrates significant performance improvements across three standard benchmark datasets (Gibson, MP3D, and HM3D)."

---  

## ğŸ”¬ 1. Model-free-I

ğŸ™Œ Official implementation of IEEE Robotics and Automation Letters accepted paper ["A New Representation of Universal Successor Features for Enhancing the Generalization of Target-driven Visual Navigation"](https://ieeexplore.ieee.org/document/10623277)

---  
#### ğŸš€ 1.1 Research Background 
- **Problem Definition**: How to address poor generalization in reinforcement learning for visual navigation task.  
- **Research Significance**: Traditional methods perform poorly in new targets or environments, lacking universality.  
- **Challenges**: Complex state spaces and diverse goal representations.

#### ğŸ›°ï¸ 1.2 Research Methods  
- The framework incorporates Successor Features into the A3C architecture.ï¼ˆDerived from cognitive science principles, SF emulates neural mechanisms for constructing reusable predictive maps. This approach achieves reward-dynamics decomposition, facilitating rapid policy adaptation to reward modifications and enabling the acquisition of transferable environmental dynamics representations across task distributions.ï¼‰ğŸ“ ä¸­æ–‡ç¿»è¯‘ï¼šå°†SFä¸A3Cç®—æ³•ç»“åˆã€‚SFæºè‡ªè®¤çŸ¥ç§‘å­¦é¢†åŸŸï¼Œæ¨¡æ‹Ÿå¤§è„‘å¦‚ä½•åˆ›å»ºå¯é‡ç”¨çš„é¢„æµ‹åœ°å›¾ã€‚å°†å¥–åŠ±å’Œç¯å¢ƒåŠ¨æ€è§£è€¦ï¼Œä½¿å¾—ç­–ç•¥å¯ä»¥å¿«é€Ÿé€‚åº”å¥–åŠ±å˜åŒ–ï¼Œèƒ½å¤Ÿå­¦ä¹ å¤šä¸ªä»»åŠ¡ä¹‹é—´å¯è¿ç§»çš„ç¯å¢ƒåŠ¨æ€è¡¨å¾ã€‚
- Implementation of state-feature-based prediction mechanisms to establish parsimonious dynamics models in latent space for SF estimation. ğŸ“ ä¸­æ–‡ç¿»è¯‘ï¼šä½¿ç”¨çŠ¶æ€ç‰¹å¾é¢„æµ‹SFæ¥åˆ›å»ºæ½œåœ¨çš„ç®€çº¦åŠ¨åŠ›å­¦æ¨¡å‹ã€‚
- Acquisition of compact rule sets within the latent state manifold to optimize successor feature prediction and extraction, enhancing the model's representational capacity.ğŸ“ ä¸­æ–‡ç¿»è¯‘ï¼šåœ¨æ½œåœ¨çŠ¶æ€ä¸­å­¦ä¹ è§„åˆ™é›†ï¼Œæœ‰åŠ©äºé¢„æµ‹å’Œè·å–åç»§ç‰¹å¾ã€‚

![Example Image](Train/figs/SF.jpg)  
  
#### ğŸ† 1.3 Experimental Results  
- **Datasets**: Tested in multiple simulation environments (e.g., AI2-THOR, Habitat). 
- **Performance Metrics**:
  - Success Rate (SR)
  - Success weighted by Path Length (SPL)
  - Continuous Learning Performance 
- **Conclusions**:
  - Achieving state-of-the-art performance in the generalization of target, scenarios, and domains.
  - Demonstrating strong resistance to catastrophic forgetting in continual learning.



## ğŸ”® 2. Model-free-II
---  
ğŸ™Œ Official implementation of IROS 2025 under-review paper "Towards Efficient Image-Goal Navigation: A Self-Supervised Transformer-Based Reinforcement Learning Approach".

#### ğŸš€ 2.1 Research Background 
- **Problem Definition**: How to improve the cross-scene and cross-domain generalization ability in visual navigation, enabling agents to effectively navigate to target locations in new environments.  
- **Research Significance**: Existing methods face challenges in handling long-term temporal information and cross-domain generalization. There is a need for more effective visual representation learning and temporal information processing methods.  
- **Challenges**:
  - Simultaneous processing of high-dimensional visual inputs and complex temporal dependencies.
  - Challenges from dynamic camera parameter settings in real-world scenarios.

#### ğŸ›°ï¸ 2.2 Research Methods  
- Designed a Transformer-based dual attention mechanism framework.
- Bidirectional attention for masked prediction learning to enhance representation capability.
-  Causal attention for generating belief states to guide policy decisions.
-  Shared Transformer network to reduce parameter count.

![Example Image](Train/figs/Masked.jpg)  

#### ğŸ† 2.3 Experimental Results  
- **Datasets**:
  - Gibson dataset (training and testing).
  - MP3D and HM3D datasets (cross-domain testing).
  - Categorized by difficulty: easy (1.5-3m), medium (3-5m), and hard (5-10m). 
- **Performance Metrics**:
  - Success Rate (SR)
  - Success weighted by Path Length (SPL)
- **Conclusions**:  
  - Achieved state-of-the-art performance on Gibson dataset, demonstrating superior navigation capabilities (SR 91.7%, SPL 68.5%).
  - Exhibited robust cross-domain generalization, maintaining consistent performance across diverse environments (MP3D: SR 79.1%, SPL 52.8%; HM3D: SR 79.1%, SPL 46.6%).
  - Demonstrated remarkable resilience to dynamic camera parameters (height: 0.8m-1.5m, pitch: Â±5Â°, FoV: 60Â°-120Â°) (Gibson SR 74.1%, SPL 48.9%).
  - Demonstrated successful real-world deployment on a mobile robot equipped with NVIDIA Jetson Xavier NX, achieving reliable navigation performance in cluttered office environments.
    

## ğŸ¯ 3. Model-basedï¼ˆWorld Modelï¼‰
---  

ğŸ™Œ Official implementation of CoRL 2025 under-preparation paper "Learning Stochastic World Models with VAE-Transformer for Visual Navigation (In Progress)"

#### ğŸš€ 3.1 Research Background  
- **Problem Definition**: How to model environmental uncertainty in visual navigation?  
- **Research Significance**: Current world models lack stochastic modeling capabilities  
- **Challenges**:  
  - Complex environmental dynamics  
  - Uncertainty quantification in navigation  

#### ğŸ›°ï¸ 3.2 Research Methods   
- Developing a VAE-Transformer hybrid architecture for world modeling  
- **Core Components**:  
  - VAE for stochastic state representation  
  - Transformer for temporal dependency modeling  
- **Key Features**:  
  - Probabilistic state transitions  
  - Uncertainty-aware planning  

#### ğŸ† 3.3 Experimental Results  
- **Metrics**:  
  - Navigation success rate under uncertainty  
  - Model prediction accuracy  
- **Potential Impact**:  
  - More robust navigation in uncertain environments  
  - Better generalization to real-world scenarios
![Example Image](Train/figs/Network.jpg)  

ğŸ—‚ï¸ [Research in progress, results pending]
